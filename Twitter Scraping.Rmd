Welcome to R Markdown. It's very similar to Jupyter notebooks, except that it's offline and has more functionality. Before you start, you'll need to make sure you have R installed. 

```{r}
#This is the first code chunk. We'll be installing several packages here. You only need to do this once. Afterwards, feel free to delete this. 

install.packages("rtweet") #This allows us to scrape tweets. 
install.packages("tidyverse") #This is like pandas and numpy. 
install.packages("readr") #For creating excel files
install.packages("readxl")

```

```{r}
#Don't delete this! You'll need to run this each time you start working. 
library(rtweet)
library(tidyverse)
library(readr)
library(readxl)
```

```{r}
#These next thing you can find on your twitter developer account. Each of us should have different ones. Make sure to put yours in quotes ' '
#Again, you need to run this chunk each time. If you do it before you insert your keys, you'll get an error. 
API_key= ''
API_secret= ''
access_token= ''
access_token_secret= ''
```

```{r, warning=FALSE}
#Now we'll get to the main part, actually getting tweets. First we need our dataset. 

#I recommend making a folder on your computer and saving this file to it. Also put all the Excel files in there. That'll make things easier. 

follower_list <- read_excel("file_name.xlsx") #Just replace file_name with the file. You need the .xlsx, or it won't work.

```

```{r}
#Here's the part that will take a while. 
#What this is doing is going through every twitter account we're getting information from and grabbing every tweet from early January until May 22nd. It's a lot. The main limit is from Twitter, which basically artificially imposes download limits to prevent people from downloading literally their entire archive. So we can get (I think) about 10,000 tweets every 15 minutes. It adds up really quickly, though- this final dataset will be big. 

#So just run it and let it go in the background. 

#If you see a warning like this: Warning: /1.1/statuses/user_timeline.json - Not authorized.
#You don't need to do anything. That means it tried to access a Twitter account that was set to private and couldn't. About 1/4-1/3 are like that. 

user_timelines <- get_timelines(follower_list$user_id, n=3200, since_id = '1469227360893427716', retryonratelimit =TRUE, include_rts=FALSE)

#After a while, it'll stop and you can go to the next chunk.  
```

```{r}
#Now we have the dataset, but we want to put it in excel. 

write_as_csv(user_timelines, "good_name_here.csv", prepend_ids = TRUE, na = "", fileEncoding = "UTF-8")
 #Just put in what you want the file to be called. Don't forget the .csv at the end! It won't work without it. It should just stick the new file into same folder as this R Studio document.
```


